{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddit GenAI Trend Analysis with ReAct Agent Framework\n",
    "\n",
    "Author: Amanda Milberg, Principal Solutions Engineer @ TitanML\n",
    "\n",
    "üéØ **Main Purpose**:\n",
    "- Analyzes r/technology subreddit posts to identify and summarize GenAI-related content\n",
    "- Generates professional summaries of AI trends and developments to send to downstream users who want to stay up to date on the latest trends\n",
    "\n",
    "üîë **Key Components**:\n",
    "1. Reddit API Integration to scrape relevant posts in a given subreddit (e.g. r/technology)\n",
    "2. LLM-powered analysis to:\n",
    "   - Determine GenAI relevance based on the thread title\n",
    "   - Summarize key themes and content for each article\n",
    "   - Generate trend analysis summary reports for all the GenAI related articles \n",
    "\n",
    "üìä **Process Flow**:\n",
    "1. Fetches hot posts from r/technology \n",
    "2. Filters for GenAI-related content\n",
    "3. Extracts and summarizes article content\n",
    "4. Creates comprehensive trend analysis\n",
    "5. Generates formatted report with sources ready to email to downstream users \n",
    "\n",
    "üõ†Ô∏è **Technologies Used**:\n",
    "- PRAW (Reddit API)\n",
    "- OpenAI API/Self-hosted LLM\n",
    "- BeautifulSoup for web scraping\n",
    "- Markdown for report formatting\n",
    "- ReAct agent framework\n",
    "\n",
    "_Note: Requires Reddit API credentials and access to a LLM to function._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Use an Agent Framework?\n",
    "\n",
    "- Implements the ReAct (Reasoning + Acting) paradigm for more transparent and controlled AI behavior\n",
    "- Provides explicit thinking and action steps for complex tasks\n",
    "- Enables better debugging and monitoring of the AI's decision process\n",
    "\n",
    "üß† **ReAct Framework Benefits**:\n",
    "1. **Reasoning Transparency**\n",
    "   - Agent explicitly shows its thinking process before actions\n",
    "   - Helps track decision-making logic\n",
    "   - Makes debugging easier\n",
    "\n",
    "2. **Structured Actions**\n",
    "   - Clear separation between thinking and execution\n",
    "   - Each action has defined inputs and outputs\n",
    "   - Better error handling and recovery\n",
    "\n",
    "3. **Process Monitoring**\n",
    "   - Logs each step of the analysis pipeline\n",
    "   - Tracks success/failure of individual components\n",
    "   - Maintains history of decisions and actions\n",
    "\n",
    "_The agent framework transforms what could be a simple script into a more robust, observable, and maintainable system for AI analysis. The agent approach provides better structure, transparency, and reliability for complex AI tasks compared to a simple main function._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Self-Host?\n",
    "\n",
    "üåü **Key Benefits of Self-Hosting** \n",
    "\n",
    "1. **Cost-Effective Performance**\n",
    "   - Reduced operational costs for high-volume processing\n",
    "   - No ongoing API fees or usage limits\n",
    "\n",
    "2. **Privacy & Data Control** \n",
    "   - Complete control over data processing and storage\n",
    "   - No data sharing with external providers\n",
    "   - Compliance with internal security policies\n",
    "   - Ability to air-gap for sensitive applications & sensitive data \n",
    "\n",
    "3. **Deployment Flexibility**\n",
    "   - Run locally on your own infrastructure\n",
    "   - Scale resources based on actual needs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Deep Seek?\n",
    "\n",
    "1. **Specialized Reasoning Capabilities**\n",
    "   - Optimized for logical reasoning and analysis tasks\n",
    "   - Efficient chain-of-thought processing\n",
    "   - Ideal for structured analytical workflows\n",
    "2. **Open Source Technology + Self-Hosting Stack = üòç**  \n",
    "   - Deepseek broke the internet \n",
    "   - Firm believer in owning your AI stack \n",
    "   - Smaller / specalized models for a given application  \n",
    "\n",
    "_Note: In this demo we are running a self-hosted [DeepSeek-R1-Distill-Llama-8B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B) deployed on 4xL4 GPUs using the [TitanML's Takeoff Stack](https://docs.titanml.co/). If you want to try this on your own you can pull this repository and swap in an OpenAI model. The code uses OpenAI compatiable endpoints so any model should be able to be swapped in. If you have any questions please reach out to: amanda.milberg@titanml.co_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions in AI Agent Architecture (or the \"Doing\")\n",
    "\n",
    "üîß **Service Functions**\n",
    "Functions that handle specific, specialized tasks like:\n",
    "- API interactions (init_reddit, init_llm)\n",
    "- Web scraping (extract_article_content)\n",
    "- Data parsing & formatting (parse_llm_response)\n",
    "- LLM analysis (analyze_genai_relevance, summarize_content, create_email_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import os\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Optional\n",
    "from openai import OpenAI\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "import functools\n",
    "from IPython.display import display, Markdown, HTML\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def retry(func, max_retries=3, delay=5):\n",
    "    \"\"\"Retry decorator with exponential backoff.\"\"\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                return func(*args, **kwargs)\n",
    "            except Exception as e:\n",
    "                if attempt == max_retries - 1:\n",
    "                    raise\n",
    "                print(f\"Attempt {attempt + 1} failed: {e}. Retrying in {delay} seconds...\")\n",
    "                time.sleep(delay)\n",
    "                delay *= 2  # Exponential backoff\n",
    "    return wrapper\n",
    "\n",
    "def extract_article_content(url: str) -> str:\n",
    "    \"\"\"Extract main content from article URL with proper headers and error handling\"\"\"\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Connection': 'keep-alive',\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, headers=headers, timeout=15)\n",
    "        response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        for script in soup([\"script\", \"style\"]):\n",
    "            script.decompose()\n",
    "        text = soup.get_text(separator=' ', strip=True)\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error extracting content: {e}\")  # More specific error\n",
    "        return \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error extracting content: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def analyze_genai_relevance(llm: OpenAI, title: str) -> dict:\n",
    "    \"\"\"Analyze if title is GenAI-related using LLM, returning JSON directly.\"\"\"\n",
    "\n",
    "    system_prompt = \"\"\"You are a helpful AI assistant. Determine if the given article title relates to Generative AI.\n",
    "\n",
    "    Return a JSON object in the following format:\n",
    "    {\n",
    "        \"is_genai_related\": true/false,\n",
    "        \"relevance_type\": \"direct/indirect/none\",\n",
    "        \"reasoning\": \"Your reasoning here...\"\n",
    "    }\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = llm.chat.completions.create(\n",
    "            model=\"meta/llama-3.1-405b-instruct\",  # Corrected model name (EXAMPLE!)\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": title}\n",
    "            ],\n",
    "            temperature=0.2,\n",
    "            top_p=0.7,\n",
    "            max_tokens=200\n",
    "        )\n",
    "        response_text = response.choices[0].message.content\n",
    "\n",
    "        # Extract JSON by finding braces\n",
    "        start = response_text.find('{')\n",
    "        end = response_text.rfind('}') + 1  # +1 to include the closing brace\n",
    "        if start == -1 or end == -1:\n",
    "            raise json.JSONDecodeError(\"No valid JSON object found\", response_text, 0)\n",
    "        json_str = response_text[start:end]\n",
    "        json_data = json.loads(json_str)\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error: Invalid JSON returned from LLM: {response_text}\\nError Detail: {e}\")\n",
    "        json_data = {\"is_genai_related\": False, \"relevance_type\": \"none\", \"reasoning\": \"\"}\n",
    "    except Exception as e: # Catch API errors here\n",
    "        print(f\"Error in GenAI relevance: {e}\")\n",
    "        json_data = {\"is_genai_related\": False, \"relevance_type\": \"none\", \"reasoning\": \"\"}\n",
    "\n",
    "    return json_data # Return the dictionary directly\n",
    "\n",
    "def summarize_trend(llm: OpenAI, title: str, content: str) -> str:\n",
    "    \"\"\"Summarize a single trend using LLM with <think> tags.\"\"\"\n",
    "\n",
    "    system_prompt = \"\"\"You are a helpful AI assistant tasked with summarizing \n",
    "    technology trends.  Provide a concise summary of the given article content.\n",
    "    Structure your response with a clear separation between your reasoning \n",
    "    process and the final summary.\n",
    "    \n",
    "    Use this format:\n",
    "    \n",
    "    <think>\n",
    "    Your step-by-step reasoning process.\n",
    "    </think>\n",
    "    \n",
    "    The final summary of the trend.\n",
    "    \"\"\"\n",
    "    \n",
    "    user_prompt = f\"\"\"Title: {title}\\n\\nContent:\\n{content}\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.chat.completions.create(\n",
    "            model = \"meta/llama-3.1-405b-instruct\", ##switch to OpenAI model (e.g. gpt-4) for OpenAI implementation \n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0.2,\n",
    "            top_p=0.7,\n",
    "            max_tokens=2000\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in trend summarization: {str(e)}\")\n",
    "        return \"\"\n",
    "\n",
    "def create_email_summary(trends_list: List[Dict], llm: OpenAI) -> str:\n",
    "    \"\"\"Create a high-level email summary of the identified GenAI trends.\"\"\"\n",
    "\n",
    "    if not trends_list:\n",
    "        return \"No GenAI trends were identified in the current batch.\"\n",
    "\n",
    "    system_prompt = \"\"\"You are a helpful AI assistant tasked with creating a high-level \n",
    "    email summary of Generative AI trends. Analyze the provided trends and generate \n",
    "    a concise summary suitable for an email. Focus on key themes, technologies, \n",
    "    and public sentiment.\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare a summary of each trend for the LLM\n",
    "    trend_summaries = \"\"\n",
    "    for trend in trends_list:\n",
    "        trend_summaries += f\"- **{trend['title']}**: {trend['summary']}\\n\"\n",
    "\n",
    "    user_prompt = f\"\"\"Analyze the following GenAI trends and provide a high-level email summary:\n",
    "\n",
    "    {trend_summaries}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = llm.chat.completions.create(\n",
    "            model=\"meta/llama-3.1-405b-instruct\",  # Or your preferred model\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0.2,\n",
    "            top_p=0.7,\n",
    "            max_tokens=2000\n",
    "        )\n",
    "\n",
    "        llm_response = response.choices[0].message.content\n",
    "\n",
    "        # Extract thinking and summary (similar to before, but could be adjusted)\n",
    "        end_think_pos = llm_response.find('</think>')\n",
    "        thinking_response = llm_response[:end_think_pos]\n",
    "        summary = llm_response[end_think_pos+9:]\n",
    "        f_thinking_response = \"### Deepseek Reasoning\\n\\n\" + thinking_response + \"\\n\\n---\\n\\n\"\n",
    "\n",
    "        # Add Further Reading section\n",
    "        further_reading = \"\\n\\n---\\n\\n### Further Reading\\n\\n\"\n",
    "        for trend in trends_list:\n",
    "            further_reading += f\"**{trend['title']}**\\n\"\n",
    "            further_reading += f\"- Source: {trend['url']}\\n\\n\"\n",
    "\n",
    "        # Combine AI analysis with Further Reading\n",
    "        complete_email = f_thinking_response + summary + further_reading\n",
    "\n",
    "        return display(Markdown(complete_email))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in trends summarization: {str(e)}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_reddit(client_id: str, client_secret: str, user_agent: str) -> praw.Reddit:\n",
    "    \"\"\"Initialize and return a Reddit client instance.\"\"\"\n",
    "    return praw.Reddit(\n",
    "        client_id=client_id,\n",
    "        client_secret=client_secret,\n",
    "        user_agent=user_agent\n",
    "    )\n",
    "\n",
    "def init_llm(api_key: str) -> OpenAI:\n",
    "    \"\"\"Initialize and return an OpenAI client instance.\"\"\"\n",
    "    return OpenAI(api_key=api_key, base_url=\"https://api.llm.ngc.nvidia.com/v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Agent Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reddit_trends(reddit: praw.Reddit, llm: OpenAI) -> List[Dict]:\n",
    "    \"\"\"Get and analyze Reddit trends, returning only GenAI-related ones.\"\"\"\n",
    "    trends = []\n",
    "    print(\"üìä Fetching posts from r/technology...\")\n",
    "    print(\"üéØ ACTION: Fetching 20 most popular threads:\")\n",
    "    print(\"=\" * 50)\n",
    "    try:\n",
    "        for submission in reddit.subreddit(\"technology\").hot(limit=20):\n",
    "            print(submission.title)\n",
    "\n",
    "            relevance = analyze_genai_relevance(llm, submission.title)\n",
    "            print(f\"GenAI Relevance: {relevance['is_genai_related']}\")\n",
    "\n",
    "            if relevance['is_genai_related']:\n",
    "                print(\"üéØ ACTION: üìñ Reading Article Details at\", submission.url)\n",
    "                print(\"=\" * 50)\n",
    "                content = extract_article_content(submission.url)\n",
    "\n",
    "                if content:  # Only proceed if content was extracted\n",
    "                    summary = summarize_trend(llm, submission.title, content)\n",
    "                    trends.append({\n",
    "                        \"title\": submission.title,\n",
    "                        \"url\": submission.url,\n",
    "                        \"summary\": summary,\n",
    "                        \"relevance_reasoning\": relevance[\"reasoning\"],  # Include reasoning\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"Skipping summarization due to empty content for: {submission.title}\")\n",
    "            else:\n",
    "                print(\"=\" * 50)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during trend gathering: {e}\")\n",
    "        return []\n",
    "\n",
    "    return trends\n",
    "\n",
    "class RedditAIAnalysisAgent:\n",
    "    def __init__(self, reddit_creds: dict, openai_api_key: str):\n",
    "        self.reddit_creds = reddit_creds\n",
    "        self.openai_api_key = openai_api_key\n",
    "        self.reddit = None\n",
    "        self.llm = None\n",
    "        self.thought_history = []\n",
    "        print(\"\\nü§ñ Initializing Reddit AI Analysis Agent...\\n\")\n",
    "\n",
    "    def think(self, thought: str):\n",
    "        \"\"\"Record agent's thinking process\"\"\"\n",
    "        self.thought_history.append({\"thought\": thought, \"timestamp\": datetime.now().isoformat()})\n",
    "        print(f\"\\nü§î THINKING: {thought}\")\n",
    "\n",
    "    def act(self, action: str, result: any):\n",
    "        \"\"\"Record agent's actions and results\"\"\"\n",
    "        self.thought_history.append({\n",
    "            \"action\": action,\n",
    "            \"result\": result,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        })\n",
    "        print(f\"üéØ ACTION: {action}\")\n",
    "        print(f\"üìù RESULT: {result}\\n\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "    def initialize_clients(self) -> bool:\n",
    "        \"\"\"Initialize Reddit and LLM clients\"\"\"\n",
    "        try:\n",
    "            print(\"\\nüì° INITIALIZING CLIENTS...\")\n",
    "            self.think(\"Need to initialize Reddit and LLM client\")\n",
    "\n",
    "            self.reddit = init_reddit(\n",
    "                self.reddit_creds['client_id'],\n",
    "                self.reddit_creds['client_secret'],\n",
    "                self.reddit_creds['user_agent']\n",
    "            )\n",
    "            self.act(\"Initialize Reddit client\", \"‚úÖ Reddit client initialized successfully\")\n",
    "\n",
    "            self.llm = init_llm(self.openai_api_key)\n",
    "            self.act(\"Initialize LLM client\", \"‚úÖ LLM client initialized successfully.\")\n",
    "\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            self.act(\"Initialize clients\", f\"‚ùå Failed: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def analyze_trends(self) -> Optional[Dict]:\n",
    "        \"\"\"Get and analyze Reddit trends\"\"\"\n",
    "        try:\n",
    "            print(\"\\nüîç ANALYZING REDDIT TRENDS...\")\n",
    "            self.think(\"Fetching Reddit trends for analysis\")\n",
    "\n",
    "            # Get trends (only GenAI-related ones)\n",
    "            trends = get_reddit_trends(self.reddit, self.llm)\n",
    "\n",
    "            if not trends:\n",
    "                self.think(\"No GenAI trends found in current batch\")\n",
    "                self.act(\"Analyze trends\", \"‚ö†Ô∏è No relevant trends found\")\n",
    "                return {\n",
    "                    \"success\": True,\n",
    "                    \"timestamp\": datetime.now().isoformat(),\n",
    "                    \"analysis\": \"No GenAI trends found.\",\n",
    "                    \"trends\": [],\n",
    "                    \"count\": 0\n",
    "                }\n",
    "\n",
    "            # Log initial processing\n",
    "            print(f\"‚úÖ Summarization complete for {len(trends)} trends\")\n",
    "\n",
    "            self.think(f\"Creating high level email summary for overall GenAI trends found\")\n",
    "            analysis = create_email_summary(trends, self.llm)\n",
    "\n",
    "            # Log completion\n",
    "            self.act(\"Create analysis\", f\"‚úÖ Analysis complete for {len(trends)} trends\")\n",
    "\n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"analysis\": analysis,\n",
    "                \"trends\": trends,\n",
    "                \"count\": len(trends),\n",
    "                \"thought_process\": self.thought_history\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            self.act(\"Analyze trends\", f\"‚ùå Failed: {str(e)}\")\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": str(e),\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"thought_process\": self.thought_history\n",
    "            }\n",
    "\n",
    "    def run(self) -> Dict:\n",
    "        \"\"\"Main execution flow with ReAct framework\"\"\"\n",
    "        print(\"\\nüöÄ STARTING REDDIT AI TREND ANALYSIS\\n\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        self.think(\"Starting Reddit AI trend analysis\")\n",
    "\n",
    "        # Initialize clients\n",
    "        if not self.initialize_clients():\n",
    "            print(\"\\n‚ùå Failed to initialize clients. Aborting...\")\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": \"Failed to initialize clients\",\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"thought_process\": self.thought_history\n",
    "            }\n",
    "\n",
    "        # Analyze trends\n",
    "        result = self.analyze_trends()\n",
    "\n",
    "        if result[\"success\"]:\n",
    "            self.think(\"Analysis complete, final report generated\")\n",
    "            print(\"\\n‚úÖ ANALYSIS COMPLETE\")\n",
    "            print(\"=\" * 50)\n",
    "            print(\"\\nFinal report has been generated in the response.\")\n",
    "        else:\n",
    "            print(\"\\n‚ùå Analysis failed. Check error details.\")\n",
    "\n",
    "        return result\n",
    "    \n",
    "def main(reddit_creds: dict, openai_api_key: str) -> dict:\n",
    "    \"\"\"Main function using ReAct agent\"\"\"\n",
    "    agent = RedditAIAnalysisAgent(reddit_creds, openai_api_key)\n",
    "    return agent.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live Demo Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Initializing Reddit AI Analysis Agent...\n",
      "\n",
      "\n",
      "üöÄ STARTING REDDIT AI TREND ANALYSIS\n",
      "\n",
      "==================================================\n",
      "\n",
      "ü§î THINKING: Starting Reddit AI trend analysis\n",
      "\n",
      "üì° INITIALIZING CLIENTS...\n",
      "\n",
      "ü§î THINKING: Need to initialize Reddit and LLM client\n",
      "üéØ ACTION: Initialize Reddit client\n",
      "üìù RESULT: ‚úÖ Reddit client initialized successfully\n",
      "\n",
      "==================================================\n",
      "üéØ ACTION: Initialize LLM client\n",
      "üìù RESULT: ‚úÖ LLM client initialized successfully.\n",
      "\n",
      "==================================================\n",
      "\n",
      "üîç ANALYZING REDDIT TRENDS...\n",
      "\n",
      "ü§î THINKING: Fetching Reddit trends for analysis\n",
      "üìä Fetching posts from r/technology...\n",
      "üéØ ACTION: Fetching 20 most popular threads:\n",
      "==================================================\n",
      "Laid-off Meta employees blast Zuckerberg in forums for running the ‚Äòcruelest tech company out there‚Äô\n",
      "Error in GenAI relevance: 404 page not found\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "Mexico‚Äôs Sheinbaum Threatens to Sue Google Over ‚ÄòGulf of America‚Äô Maps Change\n",
      "Error in GenAI relevance: 404 page not found\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "Anyone Can Push Updates to the DOGE.gov Website\n",
      "Error in GenAI relevance: 404 page not found\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "After all-hands recording leak, Meta CTO says employees who don‚Äôt agree with its policy changes should quit ‚Äî ‚ÄúIn that case you can leave or disagree and commit.‚Äù\n",
      "Error in GenAI relevance: 404 page not found\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "DOGE‚Äôs Website Is Just One Big X Ad\n",
      "Error in GenAI relevance: 404 page not found\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "DOGE Is Hacking America\n",
      "The U.S. government has experienced what may be the most consequential security breach in its history.\n",
      "Error in GenAI relevance: 404 page not found\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "Serial ‚Äúswatter‚Äù behind 375 violent hoaxes targeted his own home to look like a victim\n",
      "Error in GenAI relevance: 404 page not found\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "DOGE as a National Cyberattack\n",
      "Error in GenAI relevance: 404 page not found\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "Apple Comes Crawling Back to X Like a Dog\n",
      "Error in GenAI relevance: 404 page not found\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "Ted Cruz's list of 'woke' science includes grants to study self-driving cars and help kids watch solar eclipses\n",
      "Error in GenAI relevance: 404 page not found\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "The Trump FCC is at war with the First Amendment\n",
      "Error in GenAI relevance: 404 page not found\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "Google Maps Won't Let You Leave Negative Reviews on the Gulf of America\n",
      "Error in GenAI relevance: 404 page not found\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "U.S. State Department removes word ‚ÄòTesla‚Äô from $400 million procurement plan ‚Äî Early version of document suggested the Tesla contract, likely for ‚Äòbulletproof‚Äô Cybertruck, would be awarded at the end of September\n",
      "Error in GenAI relevance: 404 page not found\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "‚ÄúLargest data breach in US history‚Äù: Three more lawsuits try to stop DOGE | DOGE faces three more lawsuits over \"brazen ransacking\" of private data.\n",
      "Error in GenAI relevance: 404 page not found\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "UK firm recovers 97% lithium, 99% graphite from used EV batteries\n",
      "Error in GenAI relevance: 404 page not found\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "Federal workers say they increasingly distrust platforms like Facebook\n",
      "Error in GenAI relevance: 404 page not found\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "Hundreds of LGBTQI+ Resources Censored by the Trump Administration\n",
      "Error in GenAI relevance: 404 page not found\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "Lawyers Caught Citing AI-Hallucinated Cases Call It a 'Cautionary Tale' | The attorneys filed court documents referencing eight non-existent cases, then admitted it was a \"hallucination\" by an AI tool.\n",
      "Error in GenAI relevance: 404 page not found\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "NATO Plans To Build Satellite Links As Backups To Undersea Cables\n",
      "Error in GenAI relevance: 404 page not found\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "Data hoarders race to preserve data from rapidly disappearing U.S. federal websites | Websites, databases, and associated YouTube channels quickly being archived by volunteers\n",
      "Error in GenAI relevance: 404 page not found\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "\n",
      "ü§î THINKING: No GenAI trends found in current batch\n",
      "üéØ ACTION: Analyze trends\n",
      "üìù RESULT: ‚ö†Ô∏è No relevant trends found\n",
      "\n",
      "==================================================\n",
      "\n",
      "ü§î THINKING: Analysis complete, final report generated\n",
      "\n",
      "‚úÖ ANALYSIS COMPLETE\n",
      "==================================================\n",
      "\n",
      "Final report has been generated in the response.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import certifi\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file in current directory\n",
    "load_dotenv()\n",
    "\n",
    "reddit_creds = {\n",
    "    \"client_id\": os.getenv(\"REDDIT_CLIENT_ID\"),\n",
    "    \"client_secret\": os.getenv(\"REDDIT_CLIENT_SECRET\"),\n",
    "    \"user_agent\": os.getenv(\"REDDIT_USER_AGENT\")\n",
    "}\n",
    "\n",
    "nvidia_api_key = os.getenv(\"NVIDIA_API_KEY\")  # Or your OpenAI key\n",
    "\n",
    "# For debugging, you can print the certifi path:\n",
    "# print(certifi.where())\n",
    "\n",
    "result = main(reddit_creds, nvidia_api_key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
